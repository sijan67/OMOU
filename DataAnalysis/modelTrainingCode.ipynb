{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modelTrainingCode.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1jzd66TPv_706oh8gJLN3BkBYetPUs8EM","authorship_tag":"ABX9TyPC6v52imBt2B/3hQzw+51t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3ee3efac433e431db67a0fd12a96a157":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fcb627a755be4b27a9c213c7618283b2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ab0c919063da4ea49f09da0f2f4a32c5","IPY_MODEL_de898ed050494b9a836b7061742a08ac"]}},"fcb627a755be4b27a9c213c7618283b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab0c919063da4ea49f09da0f2f4a32c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c7513a5cd1bd4d00a62376c7bff98bae","_dom_classes":[],"description":"epochs: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":20,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":20,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59387be3618b43289989e6f480b273fa"}},"de898ed050494b9a836b7061742a08ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e19bb9db7204fe6a17f6be9e0bbd86f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20/20 [32:16&lt;00:00, 96.85s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f76f9424283495abbf6b73f08fe640b"}},"c7513a5cd1bd4d00a62376c7bff98bae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"59387be3618b43289989e6f480b273fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e19bb9db7204fe6a17f6be9e0bbd86f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7f76f9424283495abbf6b73f08fe640b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BtdgkEv0cNod"},"source":["# Sentence Emotion Detection Model"]},{"cell_type":"markdown","metadata":{"id":"YbsTYG6MIXT-"},"source":["Code used to make sentiment analysis model"]},{"cell_type":"code","metadata":{"id":"RWagw23Y6ZH-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618202740786,"user_tz":420,"elapsed":164620,"user":{"displayName":"Kaleb Hui","photoUrl":"","userId":"02510028260234317498"}},"outputId":"c0c5512a-31be-4854-f83a-98dc0d050237"},"source":["!pip install --upgrade torch==1.7.1 torchtext==0.8.1 torchvision==0.8.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torch==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n","\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/torchtext/\u001b[0m\n","\u001b[?25hCollecting torchtext==0.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.0MB 21.2MB/s \n","\u001b[?25hCollecting torchvision==0.8.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n","\u001b[K     |████████████████████████████████| 12.8MB 245kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n","Installing collected packages: torch, torchtext, torchvision\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","  Found existing installation: torchvision 0.9.1+cu101\n","    Uninstalling torchvision-0.9.1+cu101:\n","      Successfully uninstalled torchvision-0.9.1+cu101\n","Successfully installed torch-1.7.1 torchtext-0.8.1 torchvision-0.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4yFd3Gi6ajv4"},"source":["import torch, torchtext\n","from torch import nn, optim, functional as F\n","import pandas as pd, csv\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","import pdb\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1veCtbG6_ma","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618202742353,"user_tz":420,"elapsed":162751,"user":{"displayName":"Kaleb Hui","photoUrl":"","userId":"02510028260234317498"}},"outputId":"a1eff4ff-5469-4ffb-9117-d0dd9eaa990c"},"source":["!wget -O text.csv https://www.dropbox.com/s/iulhdbo1yc8farq/Emotion_final.csv?dl=0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-12 04:45:40--  https://www.dropbox.com/s/iulhdbo1yc8farq/Emotion_final.csv?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/iulhdbo1yc8farq/Emotion_final.csv [following]\n","--2021-04-12 04:45:40--  https://www.dropbox.com/s/raw/iulhdbo1yc8farq/Emotion_final.csv\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uce4852207e46ddab5c245a258cf.dl.dropboxusercontent.com/cd/0/inline/BMfDqv21X_gsA8kE7TAG77WqffYflzYy4hhiwxGIN60ZpzfxCqXxExbvEV_0BPD648NVaTBjsxULo7CgBR3YiW7t1g5s7savpJnD6hHFTjbsTQRfYgj-bAqyxDon-rJElHz2T-Te007SojmTAfjYuJhD/file# [following]\n","--2021-04-12 04:45:40--  https://uce4852207e46ddab5c245a258cf.dl.dropboxusercontent.com/cd/0/inline/BMfDqv21X_gsA8kE7TAG77WqffYflzYy4hhiwxGIN60ZpzfxCqXxExbvEV_0BPD648NVaTBjsxULo7CgBR3YiW7t1g5s7savpJnD6hHFTjbsTQRfYgj-bAqyxDon-rJElHz2T-Te007SojmTAfjYuJhD/file\n","Resolving uce4852207e46ddab5c245a258cf.dl.dropboxusercontent.com (uce4852207e46ddab5c245a258cf.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n","Connecting to uce4852207e46ddab5c245a258cf.dl.dropboxusercontent.com (uce4852207e46ddab5c245a258cf.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2377315 (2.3M) [text/plain]\n","Saving to: ‘text.csv’\n","\n","text.csv            100%[===================>]   2.27M  --.-KB/s    in 0.01s   \n","\n","2021-04-12 04:45:41 (172 MB/s) - ‘text.csv’ saved [2377315/2377315]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zhMpvg-g7C43"},"source":["text = pd.read_csv('/content/text.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JX_Acg6TTJ16"},"source":["sentiment = ['sadness', 'anger', 'love', 'surprise', 'fear', 'happy']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-zUfxFR8qPw"},"source":["class Sentences(torch.utils.data.Dataset):\n","    def __init__(self, fn):\n","        lengths = []\n","        convert = { u: n for n, u in enumerate(fn['Emotion'].unique()) }\n","        fn['Emotion'] = fn['Emotion'].apply(lambda u: convert[u])               # 12 unique words should be assigned integers starting from 0\n","        tokenizer = torchtext.data.utils.get_tokenizer('spacy', 'en_core_web_sm')# tokenizer using spaCy\n","        for i in range(len(fn['Text'])):\n","          lengths.append(len(tokenizer(fn['Text'].iat[i].strip())))                   # store the number of tokens in each sentence to beused in get item\n","        string = ' '.join([fn['Text'].iat[i].strip() \n","                           for i in range(len(fn['Text']))])                  # combine everything into one single string\n","        toks = tokenizer(string)                                                # tokenize the single string\n","\n","        self.vocab = torchtext.vocab.build_vocab_from_iterator([toks])\n","        self.sentiment = fn['Emotion'].values\n","        self.text = fn['Text'].values\n","        self.length = lengths\n","        self.toks = torch.LongTensor([self.vocab[tok] for tok in toks])\n","\n","    def __len__(self):\n","        return len(self.length)\n","\n","    def __getitem__(self, i):\n","        sum = 0\n","        for x in range(i):\n","          sum += self.length[x]\n","        return (self.sentiment[i], self.toks[sum: sum + self.length[i]])          # return the sentiment and related tokns for a specific tweet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MhGpWcaQ8vtu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618202748998,"user_tz":420,"elapsed":156388,"user":{"displayName":"Kaleb Hui","photoUrl":"","userId":"02510028260234317498"}},"outputId":"62c26911-8b21-43b2-ca42-1eacdcdac5b7"},"source":["ds_full = Sentences(text)\n","n_train = int(0.8 * len(ds_full))\n","n_test = len(ds_full) - n_train\n","rng = torch.Generator().manual_seed(291)\n","ds_train, ds_test = torch.utils.data.random_split(ds_full, [n_train, n_test], rng)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1lines [00:00, 20.43lines/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mWGBLBUUrgj0"},"source":["class SentenceModel(nn.Module):                                                 # takes in a sentence, and outputs predicted sentiment\n","      def __init__(self, vocab_size, embedding_dim, lstm_dim, \n","                   n_cats, n_layers = 2, drop_prob = 0.5):\n","        super().__init__()                                                      #constructor for parent class\n","        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)          #use word embeddings \n","        self.lstm = torch.nn.LSTM(embedding_dim, lstm_dim, n_layers,\n","                                  dropout=drop_prob, batch_first=True)          #LSTM layer\n","        self.linear = nn.Linear(lstm_dim, n_cats)\n","        nn.init.xavier_uniform_(self.embedding.weight.data)\n","        nn.init.xavier_uniform_(self.linear.weight.data)\n","        \n","      def forward(self, text):\n","        emb = self.embedding(text)\n","        lstm_out, _ = self.lstm(emb)\n","        out = self.linear(lstm_out)\n","        return torch.mean(out, dim=1)                                           # certain dimensions required so take mean to reduce them down"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9SdoIitGIYo"},"source":["device = torch.device('cpu')\n","\n","def run_test(model, ds, crit):\n","    preds = []                                                                  # array to store predictions\n","    batch_size = 1                                                              # change batch size here\n","    model.eval()\n","    total_loss, total_acc = 0, 0\n","    ldr = torch.utils.data.DataLoader(ds)\n","    for labs, txts in ldr:                                                \n","        labs, txts = labs.to(device), txts.to(device)\n","        with torch.no_grad():\n","            outs = model(txts)\n","            loss = crit(outs, labs)\n","            total_loss += loss.item()\n","            total_acc += (outs.argmax(1) == labs).sum().item()\n","            preds.append(outs.argmax(1))                                        # append all the predictions to an array\n","    return total_loss / len(ds), total_acc / len(ds), preds, batch_size         # added array return value 'preds' and batchsize\n","\n","def run_train(model, ds, crit, opt, sched):\n","    model.train()\n","    total_loss, total_acc = 0, 0\n","    ldr = torch.utils.data.DataLoader(ds)\n","    for labs, txts in ldr:          \n","        opt.zero_grad()\n","        labs, txts = labs.to(device), txts.to(device)\n","        outs = model(txts)                                                      \n","        loss = crit(outs, labs)\n","        loss.backward()\n","        opt.step()\n","        total_loss += loss.item()\n","        total_acc += (outs.argmax(1) == labs).sum().item()\n","    sched.step()\n","    return total_loss / len(ds), total_acc / len(ds)\n","\n","def run_all(model, test_ds, train_ds, crit, opt, sched, n_epochs=10):\n","    for epoch in tqdm(range(n_epochs), desc='epochs'):\n","        train_loss, train_acc = run_train(model, train_ds, crit, opt, sched)\n","        test_loss, test_acc, _, _ = run_test(model, test_ds, crit)\n","        tqdm.write(f'epoch {epoch}   train loss {train_loss:.6f} acc {train_acc:.4f}   test loss {test_loss:.6f} acc {test_acc:.4f}')   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402,"referenced_widgets":["3ee3efac433e431db67a0fd12a96a157","fcb627a755be4b27a9c213c7618283b2","ab0c919063da4ea49f09da0f2f4a32c5","de898ed050494b9a836b7061742a08ac","c7513a5cd1bd4d00a62376c7bff98bae","59387be3618b43289989e6f480b273fa","2e19bb9db7204fe6a17f6be9e0bbd86f","7f76f9424283495abbf6b73f08fe640b"]},"id":"80vDpIxsvTRD","executionInfo":{"status":"ok","timestamp":1618206207815,"user_tz":420,"elapsed":1685800,"user":{"displayName":"Kaleb Hui","photoUrl":"","userId":"02510028260234317498"}},"outputId":"015c07ff-e5c6-4178-a407-8e9e6656a7e7"},"source":["model = SentenceModel(len(ds_full.vocab), 64, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=0.1) #lr: 1 -> 0.1 (counteract the loss increase over time)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ee3efac433e431db67a0fd12a96a157","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='epochs', max=20.0, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["epoch 0   train loss 1.608359 acc 0.3168   test loss 1.583686 acc 0.3269\n","epoch 1   train loss 1.606533 acc 0.3162   test loss 1.583427 acc 0.3269\n","epoch 2   train loss 1.606486 acc 0.3162   test loss 1.583368 acc 0.3269\n","epoch 3   train loss 1.606475 acc 0.3161   test loss 1.583344 acc 0.3269\n","epoch 4   train loss 1.606457 acc 0.3162   test loss 1.583283 acc 0.3269\n","epoch 5   train loss 1.606383 acc 0.3161   test loss 1.583106 acc 0.3269\n","epoch 6   train loss 1.605800 acc 0.3163   test loss 1.582347 acc 0.3269\n","epoch 7   train loss 1.580952 acc 0.3430   test loss 1.643022 acc 0.4007\n","epoch 8   train loss 1.259339 acc 0.5179   test loss 1.073486 acc 0.5874\n","epoch 9   train loss 0.934875 acc 0.6407   test loss 0.759820 acc 0.7216\n","epoch 10   train loss 0.656265 acc 0.7604   test loss 0.521467 acc 0.8197\n","epoch 11   train loss 0.425697 acc 0.8469   test loss 0.382146 acc 0.8681\n","epoch 12   train loss 0.303684 acc 0.8896   test loss 0.297928 acc 0.8947\n","epoch 13   train loss 0.227618 acc 0.9138   test loss 0.274817 acc 0.9075\n","epoch 14   train loss 0.182311 acc 0.9292   test loss 0.261615 acc 0.9145\n","epoch 15   train loss 0.169039 acc 0.9390   test loss 0.278987 acc 0.9119\n","epoch 16   train loss 0.146637 acc 0.9466   test loss 0.312312 acc 0.9047\n","epoch 17   train loss 0.119592 acc 0.9548   test loss 0.299803 acc 0.9098\n","epoch 18   train loss 0.093649 acc 0.9666   test loss 0.337308 acc 0.9115\n","epoch 19   train loss 0.097270 acc 0.9664   test loss 0.292555 acc 0.9096\n","\n"],"name":"stdout"}]}]}