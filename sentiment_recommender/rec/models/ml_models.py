from tensorflow.python.keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
import os
import re
import keras
import numpy as np
import pandas as pd
from pathlib import Path

from . import ml_util

MAX_SEQUENCE_LENGTH = 250
BASE_DIR = Path(__file__).resolve().parent.parent

#user input is x -> we have to convert user input string into tensor "x"
#so input would be "input = get_weights(x, model)"
POPULARITY_WEIGHT = 1.5 # can be changed 
NUM_TRACK_OPTIONS = 25 # can be changed
POD_LABELS = ['Literature', 'Business News', 'Comedy' ,'History', 'Places & Travel']
AN_LABELS = ['Music', 'Comedy', 'Fantasy', 'Drama', 'Dementia']

tokenizer = Tokenizer(num_words=5000, lower=True)

def podcast_model(input_string):
  podcast_model = keras.models.load_model(os.path.join(BASE_DIR,r'datasets\podcast_model.h5'))
  df = pd.read_csv(os.path.join(BASE_DIR,r'datasets\podcasts.csv'))
  seq = tokenizer.texts_to_sequences([input_string])
  padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)
  pred = podcast_model.predict(padded) 
  
  pred_val = POD_LABELS[np.argmax(pred)]
  possible = df[df["Genre"] == pred_val].head(20)
  recs = pd.Series.tolist(possible["Name"])
  return np.ndarray.tolist(np.random.choice(recs, size=5, replace=False))

def anime_model(input_string):
  anime_model = keras.models.load_model(os.path.join(BASE_DIR,r'datasets\anime_model.h5'))
  df = pd.read_csv(os.path.join(BASE_DIR,r'datasets\anime_with_synopsis.csv'))
  seq = tokenizer.texts_to_sequences([input_string])
  padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)
  pred = anime_model.predict(padded)
  
  pred_val = AN_LABELS[np.argmax(pred)]
  possible = df[df["Genders"] == pred_val].head(20)
  recs = pd.Series.tolist(possible["Name"])
  return np.ndarray.tolist(np.random.choice(recs, size=5, replace=False))

def music_model(input_string):
  text = pd.read_csv(os.path.join(BASE_DIR,r'datasets\Emotion_final.csv'))
  ds_full = ml_util.Sentences(text)
  model = ml_util.SentenceModel(len(ds_full.vocab)+2, 64, 64, len(text.Emotion.unique()))

  # Model class must be defined somewhere
  model.load_state_dict(ml_util.torch.load(os.path.join(BASE_DIR,r"datasets\sentence_model_state_dict_copy.pth"), map_location=ml_util.torch.device('cpu')))
  model.eval()

  # this function calculates the appropriate probability distribution for every track based on input "tensor" and our model
  tracks = pd.read_csv(os.path.join(BASE_DIR,r"datasets/tracks.csv"))
  tracks.drop(inplace=True, columns=['duration_ms','key', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'tempo', 'time_signature', 'loudness'])
  tracks.sort_values(by=['popularity'], ascending=False)

  new_df = tracks[tracks.popularity >=65]
  scores_id = []
  seq = ds_full.input_to_tensor(input_string)
  input = ml_util.get_weights(seq, model)
  if not input.numel():
    return []
  for track in new_df.itertuples(index=False):
    score = POPULARITY_WEIGHT*(track.popularity/100) + input[0].item()*(1-track.valence) 
    + input[1].item()*track.energy + input[2].item()*((track.energy + track.danceability)/2) 
    + input[3].item()*(1-track.energy) + input[4].item()*track.valence + input[5].item()*((track.danceability + track.energy)/2)
    scores_id.append([score, track.id])

  distribution = []
  top_track_ids = []
  s = sorted(scores_id, reverse=True)
  s = s[0:NUM_TRACK_OPTIONS]

  for score, id in s:
    distribution.append(score)
    top_track_ids.append(id)
  length = len(top_track_ids) < 15 if len(top_track_ids) < 15 else 15 
  ids = np.random.choice(top_track_ids, length, p=ml_util.normalize(distribution), replace=False) # picks a random track across a distribution generated by the scores
  
  tracks = []
  for id in ids:
    # print("TRACK LINK: https://open.spotify.com/track/" + id)
    actual_track = new_df[new_df['id']==id]
    artist = re.sub(r'[\[\]\']', '', pd.Series.to_string(actual_track['artists'], index=False))
    tracks.append( artist + " - " + pd.Series.to_string(actual_track['name'], index=False))

  return tracks
