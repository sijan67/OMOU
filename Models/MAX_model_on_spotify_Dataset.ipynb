{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MAX_model_on_spotify_Dataset.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BtdgkEv0cNod"},"source":["# Sentence Emotion Detection Model\n","\n","This notebook contains code we used to train our model that uses embedding and LSTM sentiment analysis to predict the emotion of a journal entry (text sentence)"]},{"cell_type":"markdown","metadata":{"id":"44WZcyD2h912"},"source":["## Preperation"]},{"cell_type":"markdown","metadata":{"id":"sRt2g0nE6ahe"},"source":["Install SpaCy and import relevant libraries\n"]},{"cell_type":"code","metadata":{"id":"RWagw23Y6ZH-"},"source":["!pip install --upgrade torch==1.7.1 torchtext==0.8.1 torchvision==0.8.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Jq_jfHRMdoKy"},"source":["!pip install -U pip setuptools wheel\n","!pip install -U spacy\n","!python -m spacy download en_core_web_sm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"4yFd3Gi6ajv4"},"source":["import torch, torchtext\n","from torch import nn, optim, functional as F\n","import pandas as pd, csv\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","import pdb\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jAWhIAU8CqBj"},"source":["Import dataset (already cleaned) from dropbox link"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"e1veCtbG6_ma"},"source":["!wget -O text.csv https://www.dropbox.com/s/iulhdbo1yc8farq/Emotion_final.csv?dl=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zhMpvg-g7C43"},"source":["text = pd.read_csv('/content/text.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"GXDNQUiM4u1D"},"source":["text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jnm4Ly94mDN8"},"source":["Sentiments into an array for later use"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"FcNmqBVgVX1g"},"source":["text.Emotion.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"JX_Acg6TTJ16"},"source":["sentiment = ['sadness', 'anger', 'love', 'surprise', 'fear', 'happy']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvJYhc6Ohg5n"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"EaldFcmqsJWH"},"source":["Define Dataset for text and split into train/test subsets"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"P-zUfxFR8qPw"},"source":["class Sentences(torch.utils.data.Dataset):\n","    def __init__(self, fn):\n","        lengths = []\n","        convert = { u: n for n, u in enumerate(fn['Emotion'].unique()) }\n","        fn['Emotion'] = fn['Emotion'].apply(lambda u: convert[u])               # 12 unique words should be assigned integers starting from 0\n","        tokenizer = torchtext.data.utils.get_tokenizer('spacy', 'en_core_web_sm')# tokenizer using spaCy\n","        for i in range(len(fn['Text'])):\n","          lengths.append(len(tokenizer(fn['Text'].iat[i].strip())))                   # store the number of tokens in each sentence to beused in get item\n","        string = ' '.join([fn['Text'].iat[i].strip() \n","                           for i in range(len(fn['Text']))])                  # combine everything into one single string\n","        toks = tokenizer(string)                                                # tokenize the single string\n","\n","        self.vocab = torchtext.vocab.build_vocab_from_iterator([toks])\n","        self.sentiment = fn['Emotion'].values\n","        self.text = fn['Text'].values\n","        self.length = lengths\n","        self.toks = torch.LongTensor([self.vocab[tok] for tok in toks])\n","\n","    def __len__(self):\n","        return len(self.length)\n","\n","    def __getitem__(self, i):\n","        sum = 0\n","        for x in range(i):\n","          sum += self.length[x]\n","        return (self.sentiment[i], self.toks[sum: sum + self.length[i]])          # return the sentiment and related tokns for a specific tweet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"MhGpWcaQ8vtu"},"source":["ds_full = Sentences(text)\n","n_train = int(0.8 * len(ds_full))\n","n_test = len(ds_full) - n_train\n","rng = torch.Generator().manual_seed(291)\n","ds_train, ds_test = torch.utils.data.random_split(ds_full, [n_train, n_test], rng)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TygB4RsNVCsp"},"source":["Check outputs if the outputs are what we expect (tensor with integer corresponding to label and tensor of integers corresponding to tokens which can be converted to a sentence)"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"EkeLotcQc3aT"},"source":["print(ds_full[100])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"H6iblr1Bcw__"},"source":["print(ds_full[100][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"nQmQ0szjUl96"},"source":["sentiment[ds_test[100][0]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"YG1kQX4dFV-U"},"source":["print(' '.join([ds_full.vocab.itos[x] for x in ds_full[100][1]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"4_tyVYBrYd-D"},"source":["len(ds_full.toks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qqLBr9KqVIgj"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"tTBrzpJ04U1P"},"source":["Model with embedding and LSTM"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"mWGBLBUUrgj0"},"source":["class SentenceModel(nn.Module):                                                 # takes in a sentence, and outputs predicted sentiment\n","      def __init__(self, vocab_size, embedding_dim, lstm_dim, \n","                   n_cats, n_layers = 2, drop_prob = 0.5):\n","        super().__init__()                                                      #constructor for parent class\n","        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)          #use word embeddings \n","        self.lstm = torch.nn.LSTM(embedding_dim, lstm_dim, n_layers,\n","                                  dropout=drop_prob, batch_first=True)          #LSTM layer\n","        self.linear = nn.Linear(lstm_dim, n_cats)\n","        nn.init.xavier_uniform_(self.embedding.weight.data)\n","        nn.init.xavier_uniform_(self.linear.weight.data)\n","        \n","      def forward(self, text):\n","        emb = self.embedding(text)\n","        lstm_out, _ = self.lstm(emb)\n","        out = self.linear(lstm_out)\n","        return torch.mean(out, dim=1)                                           # certain dimensions required so take mean to reduce them down"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t816xISJhbAq"},"source":["Test and Train loops"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"-9SdoIitGIYo"},"source":["device = torch.device('cpu')\n","\n","def run_test(model, ds, crit):\n","    preds = []                                                                  # array to store predictions\n","    batch_size = 1                                                              # change batch size here\n","    model.eval()\n","    total_loss, total_acc = 0, 0\n","    ldr = torch.utils.data.DataLoader(ds)\n","    for labs, txts in ldr:                                                \n","        labs, txts = labs.to(device), txts.to(device)\n","        with torch.no_grad():\n","            outs = model(txts)\n","            loss = crit(outs, labs)\n","            total_loss += loss.item()\n","            total_acc += (outs.argmax(1) == labs).sum().item()\n","            preds.append(outs.argmax(1))                                        # append all the predictions to an array\n","    return total_loss / len(ds), total_acc / len(ds), preds, batch_size         # added array return value 'preds' and batchsize\n","\n","def run_train(model, ds, crit, opt, sched):\n","    model.train()\n","    total_loss, total_acc = 0, 0\n","    ldr = torch.utils.data.DataLoader(ds)\n","    for labs, txts in ldr:          \n","        opt.zero_grad()\n","        labs, txts = labs.to(device), txts.to(device)\n","        outs = model(txts)                                                      \n","        loss = crit(outs, labs)\n","        loss.backward()\n","        opt.step()\n","        total_loss += loss.item()\n","        total_acc += (outs.argmax(1) == labs).sum().item()\n","    sched.step()\n","    return total_loss / len(ds), total_acc / len(ds)\n","\n","\n","def run_all(model, test_ds, train_ds, crit, opt, sched, n_epochs=10, early_stop=False):\n","    max_test_acc = 0;\n","    for epoch in tqdm(range(n_epochs), desc='epochs'):\n","        train_loss, train_acc = run_train(model, train_ds, crit, opt, sched)\n","        test_loss, test_acc, _, _ = run_test(model, test_ds, crit)\n","        tqdm.write(f'epoch {epoch}   train loss {train_loss:.6f} acc {train_acc:.4f}   test loss {test_loss:.6f} acc {test_acc:.4f}')  \n","        if (early_stop): \n","          if (test_acc >= max_test_acc):\n","            max_test_acc = test_acc\n","          else:\n","            print(\"EARLY STOPPED\")\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6r1DbeOSgBZm"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"Xt2LUFEbCW0R"},"source":["Train model by adjusting the hyperparameters (optimizer, scheduler, learning rate, step size, gamma, dimensions etc.) to improve the model's test accuracy"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"0m5eSlLtZE12"},"source":["#TEST 1\n","\n","model = SentenceModel(len(ds_full.vocab), 32, 1, len(text.Emotion.unique()))\n","device = torch.device('cuda:0') #added GPU since CPU too slow (enable that in notebook settings)\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 10, gamma=0.1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"_7NZMMEyDB93"},"source":["#TEST 2\n","\n","model = SentenceModel(len(ds_full.vocab), 32, 1, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=0.1) #step size: 10->1\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"YMMS6MuREGot"},"source":["#TEST 3\n","\n","model = SentenceModel(len(ds_full.vocab), 32, 64, len(text.Emotion.unique())) #lstm_dim: 1 -> 64\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=0.1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"QYmiYmrXLodp"},"source":["#TEST 4\n","\n","model = SentenceModel(len(ds_full.vocab), 32, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1) #gamma: 0.1 -> 1\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"MzdX7N1-aQ80"},"source":["#TEST 5\n","\n","model = SentenceModel(len(ds_full.vocab), 32, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=0.0001) #gamma: 1 -> 0.0001\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"r45GweaZSMhc"},"source":["#TEST 6\n","\n","model = SentenceModel(len(ds_full.vocab), 32, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=3.0) #lr: 1.0 -> 3.0\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6j_NRXQlZSMD"},"source":["#TEST 7\n","\n","model = SentenceModel(len(ds_full.vocab), 32, 128, len(text.Emotion.unique())) #lstm_dim: 64 -> 128\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"v-rL0qBhosU9"},"source":["#TEST 8\n","\n","model = SentenceModel(len(ds_full.vocab), 16, 64, len(text.Emotion.unique())) #embedding_dim: 32 -> 16\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"AxPzB8LhqmeO"},"source":["#TEST 9\n","\n","model = SentenceModel(len(ds_full.vocab), 64, 64, len(text.Emotion.unique())) #embedding_dim: 16 -> 64\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"GkbkRIo1ih8v"},"source":["#TEST 10\n","\n","model = SentenceModel(len(ds_full.vocab), 128, 64, len(text.Emotion.unique())) #embedding_dim: 64 -> 128\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=1.0)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"80vDpIxsvTRD"},"source":["#TEST 11\n","\n","model = SentenceModel(len(ds_full.vocab), 64, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=0.1) #lr: 1 -> 0.1 (counteract the loss increase over time)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"b7BhLntt_wy7"},"source":["#TEST 12\n","\n","model = SentenceModel(len(ds_full.vocab), 64, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=0.001) #lr: 0.1 -> 0.001\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"-n5IfMpFtiQd"},"source":["#TEST 13\n","\n","model = SentenceModel(len(ds_full.vocab), 64, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.Adagrad(model.parameters(), lr=0.1) #optimizer: SGD -> Adagrad\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"sX64FxpyQ5fE"},"source":["#TEST 14\n","\n","model = SentenceModel(len(ds_full.vocab), 64, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.Adagrad(model.parameters(), lr=0.001) #lr: 0.1 -> 0.001\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","run_all(model, ds_test, ds_train, crit, opt, sched, 30)\n","# Testing converges at 60 epochs at 56% accuracy and 1.25 test loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UphdLqiPmBFK"},"source":["## Example Outputs"]},{"cell_type":"markdown","metadata":{"id":"ClC9RHMtv1je"},"source":["Print the desired number of outputs using code below"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"u2UQr9vfvvp8"},"source":["def print_outputs(correct_count=5, incorrect_count=5):\n","  _, _, preds, _ = run_test(model, ds_test, crit)\n","\n","  # setup variables\n","  pred = []\n","  correct = []\n","  correct_prediction = []\n","  correct_actual = []\n","  incorrect = []\n","  incorrect_prediction = []\n","  incorrect_actual = []\n","  rand_corr_idx = []\n","  rand_incorr_idx = []\n","\n","  # map results into appropriate arrays\n","  for i in range(len(preds)):\n","      pred.append(preds[i].item())                                              # transfer predictions from tensor to array\n","\n","  for x in range(len(ds_test)):                                                 # compare every prediction with the actual sentiment, move the text to their respective arrays depending on result\n","    if pred[x] == ds_test[x][0]:\n","      correct.append(ds_test[x])                                                # correctly predicted senteces move to correct array\n","      correct_prediction.append(pred[x])                                        # also store prediction\n","      correct_actual.append(ds_test[x][0])                                      # place actual labels into correct_actual array\n","    else:\n","      incorrect.append(ds_test[x])                                              # same process as correct labels, but with incorrect predictions\n","      incorrect_prediction.append(pred[x])                                        \n","      incorrect_actual.append(ds_test[x][0])\n","\n","\n","  # choose random examples from results\n","  if (correct_count > len(correct)):                                            # make sure no index out of bounds\n","    correct_count = len(correct)  \n","\n","  if (incorrect_count > len(incorrect)):\n","    incorrect_count = len(incorrect)\n","\n","  for c in range(correct_count):                                                # pick random examples from correct arr\n","    index = random.randint(0,len(correct)-1)\n","    while (index in rand_corr_idx):                                             # make sure no duplicates\n","      index = random.randint(0,len(correct)-1)\n","    rand_corr_idx.append(index)\n","\n","  for c in range(incorrect_count):                                              # pick random examples from incorrect arr\n","    index = random.randint(0,len(incorrect)-1)\n","    while (index in rand_incorr_idx):\n","      index = random.randint(0,len(incorrect)-1)\n","    rand_incorr_idx.append(index)\n","\n","  # output results\n","  print(\"CORRECT PREDICTIONS:\", len(correct), \"\\n\")                             # print correct predictions, with their actual labels and sentence\n","  for y in range(correct_count):\n","    print(\"prediction: \", sentiment[correct_prediction[rand_corr_idx[y]]])  \n","    print(\"actual:     \", sentiment[correct_actual[rand_corr_idx[y]]])\n","    print(\"sentence:   \", ' '.join([ds_full.vocab.itos[x] for x in correct[rand_corr_idx[y]][1]]), \"\\n\")\n","\n","  print('===================================================================\\n')\n","\n","  print(\"INCORRECT PREDICTIONS:\", len(incorrect), \"\\n\")                         # print incorrect predictions, with their actual labels and sentence\n","  for z in range(incorrect_count):\n","    print(\"prediction: \", sentiment[incorrect_prediction[rand_incorr_idx[z]]])  \n","    print(\"actual:     \", sentiment[incorrect_actual[rand_incorr_idx[z]]])\n","    print(\"sentence:   \", ' '.join([ds_full.vocab.itos[x] for x in incorrect[rand_incorr_idx[z]][1]]), \"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6-8VKZ8aHoe9"},"source":["num_corr_out = 10\n","num_incorr_out = 10\n","\n","print_outputs(num_corr_out, num_incorr_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m6pg6lhMs4b4"},"source":["## Conclusion"]},{"cell_type":"markdown","metadata":{"id":"pqHM1Owos8qc"},"source":["With the use of the embedding and LSTM model, I was able to achieve 91% accuracy. The hyperparameters listed below performed the best from my testing for the Emotions_final dataset. Due to the small amount of testing done so far, there is a high possibility there is a more optimized model for the respected dataset. From test 11 shown, the test loss increases over time, so decreasing test loss by lowering the learning rate or using fewer epochs will probably improve the model, which will be taken into consideration for future testing. Finally, looking at the mismatched results, some of the sentences and their corresponding labels are difficult for even a human to distinguished while other sentiments may not match the sentence either, so further cleaning of our dataset could be another strategy.\n","\n","```\n","#TEST 11\n","\n","model = SentenceModel(len(ds_full.vocab), 64, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=0.1)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aNiTFH-BBxb9"},"source":["# DO THIS FIRST IF YOU DON'T HAVE THE **DATASET**\n","\n","Also you must first run most of the code above for the model and stuff to work."]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"2g-Ko2Zj_ijw"},"source":["!pip install -q kaggle\n","from google.colab import files "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ssHvCUiBAkaI"},"source":["files.upload()\n","#here upload \"kaggle.json\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"sIsR6-Eh_lsY"},"source":["!mkdir ~/.kaggle\n","!cp /content/kaggle.json ~/.kaggle/kaggle.json\n","! chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"lx0PCDBiAueT"},"source":["!kaggle datasets download -d yamaerenay/spotify-dataset-19212020-160k-tracks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"LZtObQDADDuD"},"source":["!unzip /content/spotify-dataset-19212020-160k-tracks.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_2DDbaic16gG"},"source":["# **DATASET CODE HERE**"]},{"cell_type":"markdown","metadata":{"id":"_rLxlZKx1_HD"},"source":["upload -> sentence_model_state_dict (the saved fully trained model) \n","---\n"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ev3oeoLiW4nd"},"source":["model = SentenceModel(len(ds_full.vocab)+2, 64, 64, len(text.Emotion.unique()))\n","device = torch.device('cuda:0')\n","model.to(device);\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=0.1)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zSG7KmZ2_ulS"},"source":["# Model class must be defined somewhere\n","model.load_state_dict(torch.load(\"/content/sentence_model_state_dict.pth\"))\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"JG_wCnoCCNJC"},"source":["ldr = torch.utils.data.DataLoader(ds_test) \n","ldr.dataset[26][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"W5uQXXcEDUbl"},"source":["device = torch.device('cuda:0')\n","model.to(device)\n","crit = nn.CrossEntropyLoss().to(device)\n","opt = optim.SGD(model.parameters(), lr=0.1)\n","sched = optim.lr_scheduler.StepLR(opt, 1, gamma=1)\n","\n","with torch.no_grad():\n","    print('Tensor with ground truth label: {0}'.format(ldr.dataset[26]))\n","    out_incorrect = model(ldr.dataset[26][1].unsqueeze(0).to(device))\n","    print(out_incorrect)\n","    print(\"Predicted: {0}\".format(out_incorrect.argmax(1)))\n","    print(\"Predicted correctly: {0}\".format(out_incorrect.argmax(1) == ldr.dataset[26][0]))\n","    print(\"Tensor converted to text: \" + ' '.join([ds_full.vocab.itos[x] for x in ldr.dataset[26][1]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"qITlFNCzLP4s"},"source":["def get_weights(tensor=None, model=None): #tensor should have shape ([x, y, z, ...]) (1 dim), NOT ([[x, y, z, ...]]), the function itself unsqueezes the input tensor for you\n","  tensor = tensor.unsqueeze(0)\n","  device = torch.device('cuda:0')\n","  model.to(device)\n","  m = nn.ReLU()\n","  s = nn.Softmax(dim=1)\n","  with torch.no_grad():\n","    update_tensor = model(tensor.to(device))\n","    relud_logged = torch.log(m(update_tensor))\n","    print(relud_logged)\n","    print(\"Predicted: {0}\".format(update_tensor.argmax(1)))\n","    print(\"Tensor converted to text: \" + ' '.join([ds_full.vocab.itos[x] for x in tensor.squeeze()]))\n","    return s(relud_logged).squeeze()\n","  \n","  # this function calculates the appropriate probability distribution for every track based on input \"tensor\" and our model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"U4SYqm3ZP-1j"},"source":["x = 100\n","\n","print(ldr.dataset[x])\n","print(\"\\n\")\n","weight = get_weights(ldr.dataset[x][1], model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"CperYR9ufRXg"},"source":["print(weight)\n","weight[2].item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6lgm5scLSoFk"},"source":["tracks = pd.read_csv('/content/tracks.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"V8n0vpAtUU3d"},"source":["tracks.drop(inplace=True, columns=['duration_ms','key', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'tempo', 'time_signature', 'loudness'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"bo4_oFFTSx0W"},"source":["tracks.sort_values(by=['popularity'], ascending=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pHyGD064J7h3"},"source":["sentiment = ['sadness', 'anger', 'love', 'surprise', 'fear', 'happy']"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"kUdMFcGaciIr"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"yknXmQ8LaIo7"},"source":["# list_scores = []\n","# in = ('sadness', 'anger', 'love', 'surprise', 'fear', 'happy')\n","# for **track** in list of tracks over 65 popularity:\n","#    score = POPULARITY_WEIGHT * (track.popularity / 100) + in.sadness * (1 - track.valence) + in.anger * track.energy + in.love * (mean(track.energy + track.dancability)) + in.surprise * (1 - track.energy) + in.fear * valence + in.happy * (mean(track.danceability + track.energy))\n","#    list_scores.append(score)\n","\n","# np.random.choice(tracks, list_scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"cx3TpxS6Ypms"},"source":["new_df = tracks[tracks.popularity >=65]\n","new_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"3degcmPhlzFj"},"source":["def normalize(p): # makes sure the distribution probability list adds to 1\n","    if sum(p) != 1.0:\n","        p = np.asarray(p)*(1.0/sum(p))\n","    return p"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"TtwG6hXBdWjh"},"source":["#user input is x -> we have to convert user input string into tensor \"x\"\n","#so input would be \"input = get_weights(x, model)\"\n","\n","POPULARITY_WEIGHT = 2 # can be changed \n","NUM_TRACK_OPTIONS = 5 # can be changed\n","\n","id_tracks = new_df[\"id\"].values.tolist()\n","scores_id = []\n","input = get_weights(ldr.dataset[x][1], model)\n","for track in new_df.itertuples(index=False):\n","    score = POPULARITY_WEIGHT*(track.popularity/100) + input[0].item()*(1-track.valence) + input[1].item()*track.energy + input[2].item()*((track.energy + track.danceability)/2) + input[3].item()*(1-track.energy) + input[4].item()*track.valence + input[5].item()*((track.danceability + track.energy)/2)\n","    scores_id.append([score, track.id])\n","\n","distribution = []\n","top_track_ids = []\n","s = sorted(scores_id, reverse=True)\n","s = s[0:NUM_TRACK_OPTIONS]\n","\n","for score, id in s:\n","  distribution.append(score)\n","  top_track_ids.append(id)\n","print(\"\\n\")\n","id = np.random.choice(top_track_ids, p=normalize(distribution)) # picks a random track across a distribution generated by the scores\n","print(\"Distribution: {0}\".format(input))\n","print(\"TRACK LINK: https://open.spotify.com/track/\" + id)\n","actual_track = new_df[new_df['id']==id]\n","print(actual_track)"],"execution_count":null,"outputs":[]}]}